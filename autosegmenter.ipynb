# Load dependencies
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image, ImageTk
import matplotlib.pyplot as plt
import torch
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
import sys
sys.path.append("..")
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor
import time
import random
import warnings
import re
import requests


# Load the video
video = cv2.VideoCapture('//global.corp/data/Local/UK/Departments/RDD/Motors & Power Systems UK/SNanda/CTSegmentationDDM/348_2023_3649_MOESM1_ESM.mp4')

if not video.isOpened():
    print("Could not open video")
    exit()

# Load the autoseg model
sam_checkpoint = 'sam_vit_l_0b3195.pth'#'sam_vit_b_01ec64.pth' #"sam_vit_h_4b8939.pth" # 'sam_vit_l_0b3195.pth'
model_type = "vit_l"

device = "cuda"

sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
sam.to(device=device)

#mask_generator = SamAutomaticMaskGenerator(sam)

mask_generator = SamAutomaticMaskGenerator(
    model=sam,
    points_per_side=20,
    pred_iou_thresh=0.95,
    stability_score_thresh=0.95,
    crop_n_layers=1,
    crop_n_points_downscale_factor=1,
    min_mask_region_area=25000,  # Requires open-cv to run post-processing
)


# Function for performing both a frame isolation as well as autosegmentation
def autosegment_everything(frame, mask_generator):
    # Your image processing steps go here
    processed_frame = frame # Replace this with your actual processing steps

    masks = mask_generator.generate(processed_frame)

    return processed_frame, masks


def show_anns_temp(anns, frame_shape):
    if len(anns) == 0:
        return None
    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)

    img = np.zeros((frame_shape[0], frame_shape[1], 4), dtype=np.float32)
    for ann in sorted_anns:
        m = ann['segmentation']
        color_mask = np.concatenate([np.random.random(3), [0.35]])
        img[m] = color_mask

    return img 

def show_anns(anns, frame_shape):
    if len(anns) == 0:
        return None
    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)

    # Define 5 fixed colors
    fixed_colors = [
        np.array([1, 0, 0, 0.35]),  # Red
        np.array([0, 1, 0, 0.35]),  # Green
        np.array([0, 0, 1, 0.35]),  # Blue
        np.array([1, 1, 0, 0.35]),  # Yellow
        np.array([1, 0, 1, 0.35]),  # Magenta
    ]

    img = np.zeros((frame_shape[0], frame_shape[1], 4), dtype=np.float32)
    
    for i in range(min(5, len(sorted_anns))):  # Limit to top 5 masks
        ann = sorted_anns[i]
        m = ann['segmentation']
        color_mask = fixed_colors[i]
        img[m] = color_mask

    return img


def overlay_image(mask, background):
    mask = cv2.cvtColor(mask, cv2.COLOR_RGBA2BGRA)
    background = cv2.cvtColor(background, cv2.COLOR_BGR2BGRA)

    # Convert mask to float32 and scale it to [0,255]
    mask = (mask * 255).astype(np.float32)

    # Convert background to float32
    background = background.astype(np.float32)

    # Scalar blend by a value for the mask(s)
    alpha = 0.4

    # Perform blending
    result = cv2.addWeighted(background, 1 - alpha, mask, alpha, 0)

    # Convert the result back to uint8
    result = result.astype(np.uint8)

    return result
   


# Directory where you want to save the frames
output_dir = '//global.corp/data/Local/UK/Departments/RDD/Motors & Power Systems UK/SNanda/CTSegmentationDDM/output_vortex'

# Loop over each frame in the video
frame_counter = 0
while frame_counter < 100:
    # Read a new frame
    ret, frame = video.read()
    if not ret:
        break
      
    processed_frame, masks = autosegment_everything(frame, mask_generator)
    img = show_anns(masks, processed_frame.shape)

    if img is not None:
        # Overlay the mask on the frame
        overlaid_frame = overlay_image(img, processed_frame)

        # Convert the overlaid frame to BGR color space
        overlaid_frame_bgr = cv2.cvtColor(overlaid_frame, cv2.COLOR_RGBA2BGR)

        # Save the frame as an image file
        filename = os.path.join(output_dir, f'frame_{frame_counter:03}.png')
        cv2.imwrite(filename, overlaid_frame_bgr)

    frame_counter += 1
    # Wait for 50 ms before the next frame (corresponds to 20 FPS)
    #cv2.waitKey(50)

# Release the VideoCapture
video.release()


